{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "written-exception",
   "metadata": {},
   "source": [
    "# Tissue type classification based on microarray gene expression profiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patient-ghost",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In recently years, the explosion of data-driven methods in medical sciences have increased dramatically. For example, gene expression data has been used to help the understanding of cancer and cellular responses to drug treatment. Data obtained from cancer related gene expression studies typically consists of expression level measurements of thousands of genes. This amount of data calls for methodologies that efficiently extract relevant biological information. \n",
    "\n",
    "Previous gene expression analysis work emphasizes clustering techniques, which aim at partitioning the set of genes into subsets that are expressed similarly across different conditions. Indeed, clustering methods, have helped to identify functionally related families of genes. However, these methods limited the usage of any tissue annotation (e.g., tumor vs. normal) in the partitioning step. \n",
    "\n",
    "In this study, our aim is to predict the classification of new tissues, based on their gene expression profiles after training on examples that have been classified by an external “supervisor”. For such purpose, propose two classification methods: i) Logistic regression and ii)  Support Vector Machines** SVM (Cortes \\& Vapnik 1995, Vapnik 1999) classifier.\n",
    "\n",
    "For this study, we use a sample of the microarray data consisting of normalized relative expression of certain genes measured in different tissue. A microarray is a laboratory tool used to detect the expression of thousands of genes at the same time. DNA microarrays are microscope slides that are printed with thousands of tiny spots in defined positions, with each spot containing a known DNA sequence or gene.\n",
    "\n",
    "<img src=\"DNA_microarray.jpg\" width=800/>\n",
    "\n",
    "image source: https://www.genome.gov/about-genomics/fact-sheets/DNA-Microarray-Technology\n",
    "\n",
    "\n",
    "The full dataset can be found at https://www.ebi.ac.uk/arrayexpress/ (accession number E-MTAB-62). \n",
    "Thus, the data we are going to use consists of pairs $\\langle x_i, l_i \\rangle$, for $i = 1, \\dots, m$ in which $x_i$ is a vector in $\\mathbb{R}^m$ that describes expression values of genes/clones. The labels $l_i$ associated with $x_i$ are $\\{'disease',\\, 'normal' \\}$ \n",
    " \n",
    "In order to determine the best method for the given data, we will provide a criterion for grading the performance of each method. For this case, we compute the Accuracy, Precision, Recall & F1 Score measures, where\n",
    "\\begin{eqnarray}\n",
    "Accuracy & = & \\frac{True \\, Positive + True\\, Negatives }{True \\, Positive +False\\,positve +False\\, Negative + True\\, Negative}\\\\[5mm] \n",
    "Precision & = & \\frac{True \\, Positive }{True \\, Positive +False \\, Positve} \\\\[5mm] \n",
    "Recall & = & \\frac{True \\, Positive }{True \\, Positive +False \\, Negative} \\\\[5mm] \n",
    "F1\\, Score & = & 2 \\frac{(Recall * Precision)}{Recall + Precision}\\\\\n",
    "\\end{eqnarray}\n",
    "\n",
    "Moreover, we will provide as well training errors in both classifiers defined as \n",
    "\\begin{equation}\n",
    "    \\mathcal{E(h(\\mathbf{x}))} = \\frac{1}{m} \\sum_{i=1}^m ({y}^{(i)} - \\hat{y}^{(i)})^2.\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "Ultimately, our goal is to build logistic regression and Support Vector Machine (SVM) models for solving tissue type prediction task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occasional-dress",
   "metadata": {},
   "source": [
    "## Methods\n",
    "### Dataset.\n",
    "The dataset used in this study consist of a sample of the normalized relative expression of certain genes measured in different tissue. The full dataset can be found at https://www.ebi.ac.uk/arrayexpress/ (accession number E-MTAB-62). This sample is pre-processed by filtering 'disease' and 'normal' tissues. The resulting feature matrix $X \\in \\mathbb{R}^n_m$ where $n= 700$ and $m = 3000$. $y \\in \\mathbb{R}^n$ is a vector containing integer values 1 (for data points labled as \"disease\") and 0 (for data points labled as 'normal').   \n",
    "\n",
    "\n",
    "### Training a validating sets\n",
    "\n",
    "Typically, the scheme for validating the predictive performance of a ML model is to split the available data into two set for training the model, and  validating the performance of the trained model. The dataset used for training is referred to as the training set, and the data used for validation is referred to as the validation set. In this study the spliting ratio is 80:20.\n",
    "\n",
    "\n",
    "### Pre-processing\n",
    "\n",
    "The data is pre-processed to remove the mean and scales each feature/variable to unit variance. This operation is performed feature-wise in an independent way. In addtion, a principal component decomposition is performed to reduce the dimensionality of the dataset used and increasing interpretability while minimizing information loss. \n",
    "\n",
    "\n",
    "### Classifiers\n",
    "\n",
    "- A description of the model(s) you are using to solve your machine learning problem. Of what form are the predictor functions (include formula if applicable)? What is the loss function to be minimized or maximized (include formula if applicable). You should also include a short description of the hyperparameters that you tune to optimize the model.\n",
    "\n",
    "#### Logistic Regression\n",
    "Logistic Regression is a popular statistical model used for binary classification. Logistic regression is a **probabilistic model**. The fundamental assumption of (binary) logistic regression is that the [log-odds](https://www.statisticshowto.com/log-odds/) of a data point $\\mathbf{x}$ having label $y=1$ are linearly related to the features of the data point:\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\log \\frac{P(y=1)}{P(y=0)} = \\log \\frac{P(y=1)}{1-P(y=1)} = w_0 + \\mathbf{w}^T \\mathbf{x} = w_0 + \\sum_{i=1}^n w_i x_i.\n",
    "\\tag{3}\n",
    "\\end{equation}\n",
    "\n",
    "Here, the coefficient vector $\\mathbf{w} = \\big(w_1, w_2, \\ldots, w_n \\big)^T$ and intercept $w_0$ fully define the linear relationship between the features and the log-odds.\n",
    "\n",
    "Note that $w_0 + \\mathbf{w}^T\\mathbf{x} > 0$ when the data point is more likely to have the label $y=1$, and $w_0 + \\mathbf{w}^T\\mathbf{x} < 0$ when it is more likely that the label $y=0$. Therefore, the sign of the function $h(\\mathbf{x}) = w_0 + \\mathbf{w}^T \\mathbf{x}$ can be used to predict the label $y$ of data points. The predicted labels outputted by the logistic regression model are\n",
    "\n",
    "\\begin{equation}\n",
    " \\hat{y} = \\begin{cases} 1 & \\mbox{ for } w_0 + \\mathbf{w}^T\\mathbf{x} \\geq 0 \\\\ 0 & \\mbox{ for } w_0 + \\mathbf{w}^T\\mathbf{x} < 0 \\end{cases}.\n",
    " \\tag{4}\n",
    "\\end{equation}\n",
    "\n",
    "Given the model parameters, one can calculate the estimated probabilities of the data point $\\mathbf{x}$ belonging to each class. To calculate the probability of the data point having the label $y=1$ we solve for $P(y=1)$ in equation (3) to obtain\n",
    "\n",
    "\\begin{equation}\n",
    "P(y=1) = \\frac{1}{1 + \\exp(-w_0 -\\mathbf{w}^T \\mathbf{x})}.\n",
    "\\tag{5}\n",
    "\\end{equation}\n",
    "\n",
    "Since the label can only take the values 0 and 1, we obtain $P(y=0)$ as the probability of the complement of $P(y=1)$:\n",
    "\n",
    "\\begin{equation}\n",
    "P(y=0) = 1 - P(y=1) = 1 - \\frac{1}{1 + \\exp(-w_0 -\\mathbf{w}^T \\mathbf{x})} = \\frac{1}{1 + \\exp(w_0 + \\mathbf{w}^T \\mathbf{x})}\n",
    "\\tag{6}\n",
    "\\end{equation}.\n",
    "A logistic regression model is fitted by minimizing the average **logistic loss**\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "\\mathcal{E}(\\mathbf{w}) &=(1/m) \\sum_{i=1}^{m}\\big[ -y^{(i)}\\ln\\big(P(y=1)\\big)-(1-y^{(i)})\\ln\\big(P(y=0)\\big) \\big] \\\\ &= (1/m) \\sum_{i=1}^{m}\\big[ -y^{(i)}\\ln\\big(\\sigma(w_0 + \\mathbf{w}^{T}\\mathbf{x}^{(i)})\\big)-(1-y^{(i)})\\ln\\big(1-\\sigma(w_0 + \\mathbf{w}^{T}\\mathbf{x}^{(i)})\\big) \\big]\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "\n",
    "with respect to $\\mathbf{w}$ and $w_0$. Here, the **logistic loss** of a single data point $\\mathbf{x}^{(i)}$ with label $y^{(i)}$ is \n",
    "\n",
    "\\begin{equation}\n",
    "    \\mathcal{L}(\\mathbf{x}^{(i)},y^{(i)}) = -y^{(i)} \\ln \\big(\\sigma(w_0 + \\mathbf{w}^{T}\\mathbf{x}^{(i)})\\big)-(1-y^{(i)})\\ln\\big(1-\\sigma(w_0 + \\mathbf{w}^{T}\\mathbf{x}^{(i)})\\big),\n",
    "\\end{equation}\n",
    "\n",
    "where $\\sigma(\\mathbf{z})$ is the **sigmoid function**\n",
    "\n",
    "\\begin{equation}\n",
    "\\sigma(\\mathbf{z}) = \\frac{1}{1 + \\exp{(\\mathbf{-z})}}.\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "\n",
    "#### Support Vector Machine\n",
    "\n",
    "Support Vector Machine is a linear model for classification and regression problems. Given it's robustness and flexibility, SVM classifiers can solve linear and non-linear problems. The objective of the support vector machine algorithm is to find a hyperplane in an N-dimensional space(N — the number of features) that distinctly classifies the data points. For further, details we refer to the original paper Cortes & Vapnik 1995, Vapnik 1999)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cellular-spelling",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "rental-purse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 3004)\n"
     ]
    }
   ],
   "source": [
    "### PART 1 ###\n",
    "## Processing DATA ##\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Read in data from the csv file and store it in the data frame 'df'.\n",
    "df = pd.read_csv(\"./data/data_subset.csv\")\n",
    "\n",
    "\n",
    "# Selecting Dataframe rows on multiple conditions using loc\n",
    "\n",
    "#In this part, you will only use data points belonging to two of the four categories in the dataset\n",
    "# 'disease' and 'normal'. Consequently, you should create a new data frame that only contains the \n",
    "# data points with these labels. The new dataset should consist of 700 data points.\n",
    "\n",
    "df_two_of_the_four_categories = df.loc[(df['label'] == 'disease') | (df['label'] == 'normal')]\n",
    "\n",
    "# Check dimensions\n",
    "\n",
    "print(df_two_of_the_four_categories.shape)\n",
    "\n",
    "\n",
    "# Create numpy arrays X (feature matrix) and y (label vector) based on the data frame. \n",
    "# The feature matrix should contain the expression data and be of shape (700, 3000). \n",
    "# The label vector y should be of shape=(700,) and contain integer values 1 \n",
    "#(for data points labled as \"disease\") and 0 (for data points labled as 'normal').\n",
    "\n",
    "\n",
    "X = df_two_of_the_four_categories.iloc[:,3:-1].to_numpy()\n",
    "\n",
    "y = np.zeros(700,)\n",
    "\n",
    "for i in range(len(y)):\n",
    "    if df_two_of_the_four_categories.iloc[i, -1] == 'disease':\n",
    "        y[i]=1     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "authorized-automation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error:  0.2892857142857143\n",
      "\n",
      "\n",
      "F1 score:  0.6379168778310762\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     disease       0.73      0.68      0.70        80\n",
      "      normal       0.61      0.67      0.63        60\n",
      "\n",
      "    accuracy                           0.67       140\n",
      "   macro avg       0.67      0.67      0.67       140\n",
      "weighted avg       0.68      0.67      0.67       140\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, KFold, cross_val_predict, cross_val_score\n",
    "from sklearn.metrics import plot_confusion_matrix, mean_squared_error, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(0)\n",
    "\n",
    "K = 5\n",
    "kf = KFold(n_splits=K, shuffle=False)\n",
    "\n",
    "# Split the data with train_test_split into training and test sets (with 80:20 ratio, random_state=42). \n",
    "# Keep test set aside until final evaluation. Use training data to choose the model.\n",
    "\n",
    "# Split dataset into training and validation sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, stratify=y, random_state=42)\n",
    "\n",
    "\n",
    "# Implement PCA (using 20 components) with logistic regression:\n",
    "\n",
    "# Use Pipeline sklearn class to chain pre-processing steps \n",
    "# (StandardScaler() and PCA(n_components=20, random_state=42)) and logistic regression.\n",
    "\n",
    "\n",
    "n=20\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "classifier = Pipeline([('scaler', StandardScaler()),('pca',  PCA(n_components = n, random_state=42)),('log_reg', LogisticRegression(n_jobs=1, C=1e6, solver='lbfgs',multi_class='ovr',random_state=42, class_weight='balanced', max_iter=1e6))])\n",
    "\n",
    "# Fit the classifier using the training data\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict y using the trained classifier and the training data\n",
    "y_train_pred = classifier.predict(X_train)\n",
    "\n",
    "\n",
    "# Predict using the trained classifier and the test data\n",
    "y_pred = cross_val_predict(classifier, X_test, y_test, cv = kf)\n",
    "\n",
    "# Use cross_val_score class from sklearn.model_selection to perform 5-fold cross-validation \n",
    "# and get average F1-score (use parameters scoring='f1' and cv=5 in cross_val_score object).\n",
    "\n",
    "scores = cross_val_score(classifier, X_test, y_test, cv = kf, scoring='f1')\n",
    "\n",
    "print('Training error: ', mean_squared_error(y_train, y_train_pred))\n",
    "print('\\n')\n",
    "print('F1 score: ', sum(scores)/K)\n",
    "print('\\n')\n",
    "print(classification_report(y_test, y_pred, target_names=['disease', 'normal']))\n",
    "\n",
    "plot_confusion_matrix(classifier, X_test, y_test) \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "injured-ending",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('scale',\n",
       "                                        StandardScaler(copy=True,\n",
       "                                                       with_mean=True,\n",
       "                                                       with_std=True)),\n",
       "                                       ('PCA',\n",
       "                                        PCA(copy=True, iterated_power='auto',\n",
       "                                            n_components=20, random_state=None,\n",
       "                                            svd_solver='auto', tol=0.0,\n",
       "                                            whiten=False)),\n",
       "                                       ('clf',\n",
       "                                        SVC(C=1.0, break_ties=False,\n",
       "                                            cache_size=200, class_weight=None,\n",
       "                                            coef0=0.0,\n",
       "                                            decision_function_...\n",
       "                                            degree=3, gamma='scale',\n",
       "                                            kernel='rbf', max_iter=-1,\n",
       "                                            probability=False,\n",
       "                                            random_state=None, shrinking=True,\n",
       "                                            tol=0.001, verbose=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=1,\n",
       "             param_grid={'clf__C': [0.01, 1, 100],\n",
       "                         'clf__gamma': [0.0001, 0.001, 0.01],\n",
       "                         'clf__kernel': ['rbf', 'linear']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Part 2 \n",
    "\n",
    "# Implement PCA (using 20 components) with SVM:\n",
    "\n",
    "# Construct Pipeline object with scaler and PCA for SVM model in a similar way as for logistic regression.\n",
    "# Use training set for choosing parameters and hyperparameters. \n",
    "#Specifically, perform grid search combined with cross-validation on the Pipeline object by using the GridSearchCV class in scikit-learn.\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "n = 20\n",
    "classifier_2 = Pipeline([\n",
    "        ('scale', StandardScaler()),\n",
    "        ('PCA', PCA(n_components=n)),\n",
    "        ('clf', SVC())])\n",
    "\n",
    "# The candidate parameter values for the SVM model in your grid search should be 'C': [0.01, 1, 100] \n",
    "# and 'gamma': [1e-04, 1e-03, 1e-02]}, the number of folds used for cross-validation should be cv=5, \n",
    "# and scoring parameter f1.\n",
    "\n",
    "\n",
    "param_grid = dict(clf__C = [0.01, 1, 100] ,\n",
    "                  clf__gamma = [1e-04, 1e-03, 1e-02],\n",
    "                  clf__kernel=['rbf','linear'])\n",
    "\n",
    "grid = GridSearchCV(classifier_2, param_grid=param_grid, cv=5, n_jobs=1, scoring= 'accuracy')\n",
    "grid.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "congressional-silly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error:  0.19285714285714287\n",
      "\n",
      "\n",
      "Best score:  0.8071428571428572\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     disease       0.84      0.81      0.83        80\n",
      "      normal       0.76      0.80      0.78        60\n",
      "\n",
      "    accuracy                           0.81       140\n",
      "   macro avg       0.80      0.81      0.80       140\n",
      "weighted avg       0.81      0.81      0.81       140\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Report F1-score of SVM model with best parameter values for C and gamma.\n",
    "\n",
    "best_model = grid.best_estimator_\n",
    "best_model_score=best_model.score(X_test, y_test)\n",
    "\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "#print(best_model)\n",
    "print('Training error: ', mean_squared_error(y_test, y_test_pred))\n",
    "print('\\n')\n",
    "print('Best score: ', best_model_score)\n",
    "print('\\n')\n",
    "print(classification_report(y_test, y_test_pred, target_names=['disease', 'normal']))\n",
    "\n",
    "plot_confusion_matrix(best_model, X_test, y_test) \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "better-literacy",
   "metadata": {},
   "source": [
    "### Discussion / Conclusion\n",
    "\n",
    "In this study, the tissue classification based on expression data was approached. In this approach, two classification methods were implemented to  classify  the microarray data consisting of normalized relative expression of certain genes measured in different tissue. The original data was preprocessed following the protocol presented in the methods section. The classification methods used in this study were logistic regression and supported vector machine.\n",
    "\n",
    "For assessing the performance of the choicen methods, we conducted a 5-fold Cross-validation. A Cross-validation is a statistical method used to estimate the skill of machine learning models. For determining the performance, we computed the Accuracy, Precision, Recall & F1 Score measures. (This scores are presented in the sections above).\n",
    "\n",
    "For the reported scores, we conclude that the SVM classifier behaves better given the data. This means that 80% of accuracy in contrast to 60% of the logistic regression. \n",
    "\n",
    "To conclude, we note that the appoaches in this study are rather simplistic and further refinement the classification can be made. For example, the SVM classifer used in this implementation uses a linear kernel in a addition to a more exhaustive grid search. As for the logistic regression method, these options should be also considered. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serious-arctic",
   "metadata": {},
   "source": [
    "## To be continue to the 4. classes problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entitled-wonder",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
